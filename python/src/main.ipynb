{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1c8e74-659c-4624-926c-12fcc27895b2",
   "metadata": {},
   "source": [
    "Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd91d8c-be40-4c4f-b55a-2aa13f2708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "# Add more imports in this block later. There will need to be several \"from sklearn.whatever import something\" lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4168c99b-3a35-4dd1-a31c-f4daaae1880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo('.', search_parent_directories = True)\n",
    "root = repo.working_tree_dir\n",
    "\n",
    "# The sample id and the log-transformed gene expression values.\n",
    "half_data_1 = pd.read_csv(root + '\\\\data\\\\RKNGHStress.csv')\n",
    "half_data_1 = half_data_1.loc[:, half_data_1.columns.str.startswith(('Sample', 'Log'))]\n",
    "half_data_1 = half_data_1.rename(columns = {'Sample' : 'sample', 'Log16S' : 'bact', 'Logcbblr' : 'cbblr', 'Log18S' : 'fungi', 'Logphoa' : 'phoa', 'Logurec' : 'urec'})\n",
    "\n",
    "# The hyperspectral measurements for each sample\n",
    "half_data_2 = pd.read_csv(root + '\\\\data\\\\RKNGHStressPCAPSR.csv')\n",
    "half_data_2 = half_data_2.rename(columns = {'Unnamed: 0' : 'sample'})\n",
    "\n",
    "data = half_data_1.join(half_data_2.set_index('sample'), on = 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d2cc1-a33c-43bc-b1dd-72b2ed921d26",
   "metadata": {},
   "source": [
    "TEMP: testing manual construction of models with specific hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590160bb-bbbd-4c7a-bbba-4b892c5ac65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['sample', 'bact', 'cbblr', 'fungi', 'phoa', 'urec'], axis = 1)\n",
    "bact = data[['bact']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389c2476-08f3-419f-8f01-9be461b04156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4792530347735706"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, bact_train, bact_test = train_test_split(X.to_numpy(), bact.to_numpy(), train_size = 0.8, random_state = 0)\n",
    "bact_train = scale(bact_train.ravel())\n",
    "bact_test = scale(bact_test.ravel())\n",
    "\n",
    "# Note: do NOT scale X and y before splitting, since that is a data leak. Instead, use the pipeline to scale both Xs and the y training, and manually scale the y testing for custom scoring like RMSE.\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), ElasticNetCV(alphas = [0.001389495], l1_ratio = 0.4285714, cv = 10, selection = 'random', max_iter = 10000))\n",
    "pipeline.fit(X_train, bact_train)\n",
    "pipeline.score(X_test, bact_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f46efa-9605-446e-bc1d-91afb144bbe6",
   "metadata": {},
   "source": [
    "This looks weird. None of the folds are converging (true for 10 folds, 5 folds, or even just 1 fold with basic ElasticNet) but changing selection to 'random' and max_iter to 10k allowed convergence. \n",
    "\n",
    "The score is pretty low. But what metric is the score? If it's not RMSE it's not in the ballpark of the R version. (UPDATE: It's R^2, so it's a bunch of pretty bad scores, actually.)\n",
    "\n",
    "It looks like ElasticNetCV, and ElasticNet for that matter, don't allow changing the scoring or tuning metric, or at least it's not obvious how. Can the models be evaluated on RMSE just by calling the RMSE function on the preds and targets? Also, does it even make sense to change the tuning metric for this algorithm? (Idk, you probably COULD, but minimizing the sum of squared residuals is good enough.) And what tuning metric does the tidymodels implementation use?\n",
    "\n",
    "This all might be caused by using the hyperparameter optima found in the R code, but that had a differet train/test split. So it's not optimal here, but it's still probably pretty good, especially since in the analysis of part 1's hyperparameters, there wasn't much variation among the elastic net models' penalties (all tending to be very close to 0) or mixtures (a bit more spread but similar).\n",
    "\n",
    "What happens if some of its own tuning were allowed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c828750-f67b-460c-b8d8-94fd1b31a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds on X_test\n",
      "[ 0.69569189 -0.87535893 -0.25776621  0.10517769 -0.59273765  0.56006148\n",
      " -0.71385707 -0.36592773  0.38387765 -0.78304772  0.72022199  0.53128687\n",
      "  0.44129921 -0.25786282  0.58056445  1.1809667  -0.26491401  0.28681619\n",
      " -0.21919771 -0.02986261  0.70315128 -0.90777818  0.84088154 -0.88865849\n",
      " -0.07234446 -0.36263674  1.23544489  1.36681226 -0.54173563  0.7090774\n",
      "  0.06410912 -0.50085058 -0.01977494 -0.24642616  0.48992319  0.64504155\n",
      "  0.31157215 -0.43514807  0.58307725 -0.89992968 -0.11740088 -0.80549581\n",
      "  0.1547279   0.63949601 -0.21470968  1.06626484 -0.22108812 -0.40188409\n",
      "  0.67753521 -0.68300371 -0.78264341  0.13862848 -1.15747476  0.49203234\n",
      " -0.76123458 -0.91494976  0.99742168  0.71968777  1.04475761  0.81154076\n",
      "  0.30913917 -0.90586621  0.90451355 -0.48645285  0.33667892 -0.71946542\n",
      "  0.51476301  0.77696631  0.23896917  0.43912973  0.00535966 -0.77178784\n",
      "  1.13765297  0.95179409  0.45859737  0.81837057 -0.30785301 -0.80467148\n",
      " -0.70438419 -0.94757898]\n",
      "\n",
      "Scaled bact_test\n",
      "[ 1.19747125 -1.33580422 -1.08364641 -0.93598194 -0.94470304  0.6966849\n",
      "  1.06223171 -1.03163522  0.66518809 -0.97982753  0.34677478  1.19747125\n",
      "  1.01977407 -1.5418692   0.81193637  1.07568414 -0.7332916   0.66518809\n",
      " -1.39907607 -0.93598194  0.52313374 -0.45787951  1.15199398 -1.08364641\n",
      "  0.52313374 -0.92396546  0.40971206  0.59442764 -2.01033072  0.75991946\n",
      "  1.36567649 -1.19699228 -1.26759475 -1.09605374  0.39178827  0.40971206\n",
      "  0.90993149  1.36567649  0.52313374  0.13433324  0.75991946 -1.1456462\n",
      "  1.30782256  0.4705535  -1.30073572  0.77437984 -0.37605492 -1.01505456\n",
      "  1.06223171 -1.51020621 -0.94470304  0.66518809 -0.7332916   1.36567649\n",
      " -1.24620036 -1.24854458  0.77437984  0.81193637  1.25914424  0.54566364\n",
      "  1.30781145 -1.04068529  0.4705535  -1.26918367 -1.06774871 -0.37605492\n",
      "  0.79332721  1.30782256  1.37069775 -0.92396546  1.30782256 -1.03163522\n",
      "  0.39178827  1.39037428  0.63600435  0.81193637 -0.51719672 -1.19699228\n",
      " -0.51719672 -0.96663487]\n",
      "\n",
      "RMSE\n",
      "0.7216279964264336\n",
      "\n",
      "RMSE, no scaling bact_test\n",
      "0.7216279964264342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Preds on X_test')\n",
    "print(pipeline.predict(X_test))\n",
    "print()\n",
    "print('Scaled bact_test')\n",
    "print(scale(bact_test))\n",
    "print()\n",
    "\n",
    "# print('MSE')\n",
    "# mse = mean_squared_error(scale(bact_test), pipeline.predict(X_test))\n",
    "# print(mse)\n",
    "\n",
    "print('RMSE')\n",
    "rmse = root_mean_squared_error(scale(bact_test), pipeline.predict(X_test))\n",
    "print(rmse)\n",
    "print()\n",
    "\n",
    "# print('MSE, no scaling bact_test')\n",
    "# mse1 = mean_squared_error(bact_test, pipeline.predict(X_test))\n",
    "# print(mse1)\n",
    "# print()\n",
    "\n",
    "print('RMSE, no scaling bact_test')\n",
    "rmse1 = root_mean_squared_error(bact_test, pipeline.predict(X_test))\n",
    "print(rmse1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23386e86-b543-4d9a-943f-dd7f622db698",
   "metadata": {},
   "source": [
    "Uh oh, RMSE of 0.83 is really bad. It doesn't even come close to the R models. What happened?\n",
    "\n",
    "Looking at the results, it looks like the scaling isn't happening for some reason, or at least not for the predictions. They're all in the 9 range instead of 0 range. Recalculating RMSE after removing scaling on bact_test gave more reasonable results.\n",
    "\n",
    "But the problem is, we want to be able to compare models among different targets using a common scale, so normalization has to be done with respect to other targets (but NOT the entire dataset for each column since that's data leakage). This should be done before training. But how can this be implemented? (UPDATE: Fixed by manually scaling bact_train and bact_test, separately. But still doesn't solve the issue of getting much higher RMSE than expected.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aaf973-4ffc-48af-a0dd-f0534194228a",
   "metadata": {},
   "source": [
    "Now try to get the distance filter up and running. This is subtly different than the correlation filter, which is probably too heavy-handed on this data. But the other aspect to consider is that the distance filter can't be applied during preprocessing (before building models) like the correlation filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e466a7-4046-4fd9-82f5-1044b6d32d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
