{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd91d8c-be40-4c4f-b55a-2aa13f2708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn_genetic import GAFeatureSelectionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c35222-7cae-4d10-8aa1-93889b0117f6",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3d6faae-0195-426f-90d5-db5b48f055dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing whether using data_consol.csv helps anything. If so, probably indicates an error in reading in or joining the separate CSVs before\n",
    "repo = git.Repo('.', search_parent_directories = True)\n",
    "root = repo.working_tree_dir\n",
    "\n",
    "data_consol = pd.read_csv(root + '//data/data_consol.csv')\n",
    "\n",
    "SEED = 0\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Intended for reproducible GA steps\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "X = data_consol.filter(regex=\"^[0-9]+$\")\n",
    "    \n",
    "# Note: do NOT scale X and y before splitting, since that is a data leak. Instead, use the pipeline to scale both Xs, and separately scale the y for custom scoring like RMSE.\n",
    "X_train, X_test, y_train_unscaled, y_test_unscaled = train_test_split(data_consol.filter(regex=\"^[0-9]+$\").to_numpy(), data_consol.filter(regex=\"pcr_[a-z]+_log\"), train_size=0.8, random_state=0)\n",
    "\n",
    "# Separate y by genes. Reshaping necessary for the y scaling step\n",
    "bact_train_unscaled = y_train_unscaled[\"pcr_bact_log\"].to_numpy().reshape(-1,1)\n",
    "bact_test_unscaled = y_test_unscaled[\"pcr_bact_log\"].to_numpy().reshape(-1,1)\n",
    "\n",
    "cbblr_train_unscaled = y_train_unscaled[\"pcr_cbblr_log\"].to_numpy().reshape(-1,1)\n",
    "cbblr_test_unscaled = y_test_unscaled[\"pcr_cbblr_log\"].to_numpy().reshape(-1,1)\n",
    "\n",
    "fungi_train_unscaled = y_train_unscaled[\"pcr_fungi_log\"].to_numpy().reshape(-1,1)\n",
    "fungi_test_unscaled = y_test_unscaled[\"pcr_fungi_log\"].to_numpy().reshape(-1,1)\n",
    "\n",
    "urec_train_unscaled = y_train_unscaled[\"pcr_urec_log\"].to_numpy().reshape(-1,1)\n",
    "urec_test_unscaled = y_test_unscaled[\"pcr_urec_log\"].to_numpy().reshape(-1,1)\n",
    "\n",
    "# Special case: phoa has 10 NAN rows that need to be removed from both its X and y.\n",
    "phoa_data = data_consol.filter(regex=\"^[0-9]+$|pcr_phoa_log\").dropna()\n",
    "X_phoa = phoa_data.to_numpy()[:,:2151]\n",
    "phoa = phoa_data[\"pcr_phoa_log\"].to_numpy()\n",
    "X_phoa_train, X_phoa_test, phoa_train_unscaled, phoa_test_unscaled = train_test_split(X_phoa, phoa, train_size=0.8, random_state=0)\n",
    "phoa_train_unscaled = phoa_train_unscaled.reshape(-1,1)\n",
    "phoa_test_unscaled = phoa_test_unscaled.reshape(-1,1)\n",
    "\n",
    "# Scale each y with respect to its distribution\n",
    "\n",
    "bact_scaler = StandardScaler()\n",
    "bact_train = bact_scaler.fit_transform(bact_train_unscaled).reshape(-1,1)\n",
    "bact_test = bact_scaler.transform(bact_test_unscaled).reshape(-1,1)\n",
    "\n",
    "cbblr_scaler = StandardScaler()\n",
    "cbblr_train = cbblr_scaler.fit_transform(cbblr_train_unscaled).reshape(-1,1)\n",
    "cbblr_test = cbblr_scaler.transform(cbblr_test_unscaled).reshape(-1,1)\n",
    "\n",
    "fungi_scaler = StandardScaler()\n",
    "fungi_train = fungi_scaler.fit_transform(fungi_train_unscaled).reshape(-1,1)\n",
    "fungi_test = fungi_scaler.transform(fungi_test_unscaled).reshape(-1,1)\n",
    "\n",
    "phoa_scaler = StandardScaler()\n",
    "phoa_train = phoa_scaler.fit_transform(phoa_train_unscaled).reshape(-1,1)\n",
    "phoa_test = phoa_scaler.transform(phoa_test_unscaled).reshape(-1,1)\n",
    "\n",
    "urec_scaler = StandardScaler()\n",
    "urec_train = urec_scaler.fit_transform(urec_train_unscaled).reshape(-1,1)\n",
    "urec_test = urec_scaler.transform(urec_test_unscaled).reshape(-1,1)\n",
    "\n",
    "# 5-fold CV; random state 0\n",
    "cv_5_0 = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Used for waveband selection\n",
    "wvs = np.arange(350,2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92808522-e1a1-4167-842a-913c8fadcd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is only with respect to X_train, not any of the target variables, this only has to be computed once. (It's relatively cheap to compute, but this also has the benefit of preserving the random choices.)\n",
    "def cluster(X_train):\n",
    "    \"\"\" Uses agglomerative clustering with a distance threshold of 0.999 on the normalized feature correlation coefficient matrix. Then, it randomly selects one waveband from each cluster.\n",
    "    This should be used as a preprocessing step when doing permutation importance. (Clustering method) \"\"\"\n",
    "    corr = np.corrcoef(X.T) # X needs to be transposed because of corrcoef's implementation\n",
    "    agg = AgglomerativeClustering(n_clusters=None, distance_threshold=0.999) # The distance threshold is somewhat arbitrary, but it's based on EDA and domain knowledge, and the results seem reasonable.\n",
    "    clusters = agg.fit_predict(corr)\n",
    "    # Now select a single \"representative\" waveband from each cluster\n",
    "    cluster_choices = []\n",
    "    for i in range(np.max(clusters)):\n",
    "        wv_in_cluster = wvs[clusters==i]\n",
    "        cluster_choices.append(rng.choice(wv_in_cluster))\n",
    "    cluster_choices = np.sort(np.array(cluster_choices))\n",
    "    return cluster_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43ac874-fce3-4b88-b42e-00897bae084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_choices = cluster(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af80f2e2",
   "metadata": {},
   "source": [
    "**The major pipeline components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96e4672-3926-402d-b16c-85ec2caa98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net = ElasticNet(fit_intercept=False, warm_start=True, random_state=0, selection='random', max_iter=4000)\n",
    "\n",
    "# Used for embedded feature importance (via coeffs) and wrapper feature importance (via perm importance)\n",
    "pipe_elastic_net = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"elastic_net\", elastic_net)\n",
    "    ],\n",
    "    memory = root+'\\\\cache',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Hyperparameters for elastic net tuning. When code is finalized, expand for more thorough search using more computational resources.\n",
    "REGULARIZATION = np.logspace(-5, 0, 8)\n",
    "MIXTURE = np.linspace(0.001, 1, 8)\n",
    "PARAM_GRID = [\n",
    "    {\n",
    "        \"elastic_net__alpha\": REGULARIZATION,\n",
    "        \"elastic_net__l1_ratio\": MIXTURE\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d64d3-904a-4f44-a923-cb8ce27dd59a",
   "metadata": {},
   "source": [
    "**Feature selection functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef09dedf-8f50-4c85-951d-c911328949bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mi(X_train, y_train, n_features=64):\n",
    "    \"\"\" Uses mutual information to calculate the n_features most related features in X_train to y_train. (Filter method) \"\"\"\n",
    "    y_train = y_train.ravel()\n",
    "    mi = mutual_info_regression(X_train, y_train)\n",
    "    top_n_idx = np.argpartition(mi, -n_features)[-n_features:]\n",
    "    return wvs[top_n_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c05613-121e-4666-ba40-c285cf7c4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elastic_net(X_train, y_train):\n",
    "    \"\"\" Builds and fits an elastic net model using all features. \n",
    "    Returns the fit estimator (a pipeline). Used within coeffs() and ga(). \"\"\"\n",
    "    grid = GridSearchCV(estimator=pipe_elastic_net, param_grid=PARAM_GRID, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=cv_5_0, error_score='raise')\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e5f4d2-3b6f-433f-92df-b2c8279ba4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeffs(estimator, n_features=64):\n",
    "    \"\"\" Builds and fits an elastic net model using all features. Returns the n_features features with the highest absolute-valued coefficients. (Embedded method) \"\"\"\n",
    "    coeffs = estimator['elastic_net'].coef_\n",
    "    abs_coeffs = np.abs(coeffs)\n",
    "    top_n_idx = np.argpartition(abs_coeffs, -n_features)[-n_features:]\n",
    "    return wvs[top_n_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693601be-723e-4ce0-b1a5-676fbdd59413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ga(X_train, y_train, trained_estimator, n_features=64, wv_subset=None):\n",
    "    \"\"\" Uses a genetic algorithm to find the wavebands that gives the lowest RMSE on an elastic net model. \n",
    "    The subset will be at most n_features large, but it may be less than n_features large. \n",
    "    wv_subset should be None when in the feature selection layer, but when in the consolidation layer, it should\n",
    "    be the subset of possible wavelengths output by the concatenated feature selection methods, not the entire\n",
    "    [350,2500] set. (GA method) \"\"\"\n",
    "    \n",
    "    y_train = y_train.ravel()\n",
    "    ga_selector = GAFeatureSelectionCV(\n",
    "        estimator=trained_estimator,\n",
    "        cv=cv_5_0,  # Cross-validation folds\n",
    "        scoring=\"neg_root_mean_squared_error\",  # Fitness function (maximize accuracy)\n",
    "        population_size=n_features*2,  # Number of individuals in the population\n",
    "        generations=50,  # Number of generations\n",
    "        n_jobs=-1,  # Use all available CPU cores\n",
    "        verbose=False,\n",
    "        max_features=n_features,\n",
    "        return_train_score=True,\n",
    "        refit=False,\n",
    "        crossover_probability=0.8,\n",
    "        mutation_probability=0.2\n",
    "    )\n",
    "    pipe_ga = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"ga\", ga_selector)\n",
    "        ], \n",
    "        memory = root+'\\\\cache',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    pipe_ga.fit(X_train, y_train)\n",
    "    feats = pipe_ga['ga'].best_features_ # A mask of the features selected from X_train\n",
    "\n",
    "    # Should be the case in the feature selection layer\n",
    "    if wv_subset is None:\n",
    "        return wvs[feats]\n",
    "    # Should be the case in the consensus layer\n",
    "    else:\n",
    "        return wv_subset[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78bd175-1cf6-4533-a305-dacce062f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_imp(X_train, y_train, n_features=64):\n",
    "    \"\"\" Calculates permutation importance on a dataset. cluster_choices should be the result of calling cluster(), which should be done once at the start of execution. \n",
    "    This is done outside this function to preserve the random selection. Returns the set of n_features wavebands with the highest permutation importance on the training set. (Wrapper method) \"\"\"\n",
    "    # Use only the features selected by clustering\n",
    "    cluster_idx = cluster_choices - 350\n",
    "    X_train = X_train[:,cluster_idx]\n",
    "    # Build and train another elastic net model, but only on the features left after clustering, to use for permutation importance.\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"elastic_net\", elastic_net)\n",
    "        ], \n",
    "        memory = root+'\\\\cache',\n",
    "        verbose=False\n",
    "    )    \n",
    "    grid = GridSearchCV(estimator=pipe, param_grid=PARAM_GRID, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=cv_5_0, error_score='raise')\n",
    "    grid.fit(X_train, y_train)\n",
    "    perm_imp = permutation_importance(grid, X_train, y_train, scoring='neg_root_mean_squared_error', n_repeats=10, n_jobs=-1, random_state=0)\n",
    "    pi_top_64_idx = np.argpartition(perm_imp.importances_mean, -64)[-64:]\n",
    "    return cluster_choices[pi_top_64_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465453b6-7b18-40c6-b88a-502d1a9f4c9e",
   "metadata": {},
   "source": [
    "**Consensus function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ed9401-293e-4afd-82e3-45e57f1bccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consensus(X_train, y_train, n_features_intermed=64, max_features_output=8):\n",
    "    \"\"\" Takes the wavebands output by the feature selection functions and uses a (separate) genetic algorithm to find the wavebands that give the lowest RMSE on an elastic net model.\n",
    "    The subset will be at most n_features large, but it may be less than n_features large.\n",
    "    Returns the tuple: (wv_mi, wv_coeffs, wv_ga, wv_cluster, wv_perm_imp, wv_consensus), where each is a numpy array of wavebands that were selected by each method.  (Consensus method) \"\"\"\n",
    "    \n",
    "    print('\\tFEATURE SELECTION:')\n",
    "    print('\\tStarting mutual importance...', end=' ')\n",
    "    wv_mi = mi(X_train, y_train, n_features=n_features_intermed)\n",
    "    print('Done.')\n",
    "    print('\\tTraining the elastic net model...', end=' ')\n",
    "    trained_pipe = train_elastic_net(X_train, y_train)\n",
    "    wv_coeffs = coeffs(trained_pipe, n_features=n_features_intermed)\n",
    "    print('Done.')\n",
    "    print('\\tStarting genetic algorithm...', end=' ')\n",
    "    wv_ga = ga(X_train, y_train, trained_pipe, n_features=n_features_intermed)\n",
    "    print('Done.')\n",
    "    print('\\tStarting permutation importance...', end=' ')\n",
    "    wv_cluster = cluster_choices # Doesn't require a separate function call\n",
    "    wv_perm_imp = perm_imp(X_train, y_train, n_features=n_features_intermed)\n",
    "    print('Done.')\n",
    "\n",
    "    # Compile the above results into one array, remove any duplicates, and sort.\n",
    "    wv_intermed = np.append(wv_mi, wv_coeffs)\n",
    "    wv_intermed = np.append(wv_intermed, wv_ga)\n",
    "    wv_intermed = np.append(wv_intermed, wv_cluster)\n",
    "    wv_intermed = np.append(wv_intermed, wv_perm_imp)\n",
    "    wv_intermed = np.sort(np.unique(wv_intermed))\n",
    "\n",
    "    # Convert the above into indices for masking over the dataset.\n",
    "    wv_intermed_idx = wv_intermed-350\n",
    "    X_train = X_train[:,wv_intermed_idx]\n",
    "\n",
    "    # Use another genetic algorithm to find the best wavebands out of the narrowed possibilities\n",
    "    print('\\tCONSENSUS:')\n",
    "    print('\\tStarting genetic algorithm...', end=' ')\n",
    "    wv_consensus = ga(X_train, y_train, trained_pipe, n_features=max_features_output, wv_subset=wv_intermed)\n",
    "    print('\\tDone.')\n",
    "    return (wv_mi, wv_coeffs, wv_ga, wv_cluster, wv_perm_imp, wv_consensus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a49f65f-065b-47fc-b4f1-4eeb463189df",
   "metadata": {},
   "source": [
    "**The \"main\" function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d5e1a93-cf0d-4df9-9166-deb913ef0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Would normally be in the main function, but defined separately for easier testing, debugging, and analysis after running within a Jupyter notebook.\n",
    "def run():\n",
    "    # Lists of results that will be compiled at the end into a DataFrame for writing to CSV\n",
    "    gene_list = []\n",
    "    method_list = []\n",
    "    wv_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    # Loop over each gene (y value)\n",
    "    for gene, y_train, y_test in zip((\"phoa\", \"cbblr\", \"fungi\", \"bact\", \"urec\"), (phoa_train, cbblr_train, fungi_train, bact_train, urec_train), (phoa_test, cbblr_test, fungi_test, bact_test, urec_test)):\n",
    "\n",
    "        print(\"Starting \", gene, \"...\", sep = \"\")\n",
    "        \n",
    "        # Where the main calculations happen. Runs each method separately, and then finds the consensus of all of them.\n",
    "        # The phoa special case is due to a different train/test split than the rest because of some NANs.\n",
    "        if(gene == \"phoa\"):\n",
    "            wv_mi, wv_coeffs, wv_ga, wv_cluster, wv_perm_imp, wv_consensus = consensus(X_phoa_train, y_train)\n",
    "        else:\n",
    "            wv_mi, wv_coeffs, wv_ga, wv_cluster, wv_perm_imp, wv_consensus = consensus(X_train, y_train)\n",
    "        \n",
    "        for method, wv_set in zip((\"mi\", \"coeffs\", \"ga\", \"cluster\", \"perm_imp\"), (wv_mi, wv_coeffs, wv_ga, wv_cluster, wv_perm_imp, wv_consensus)):\n",
    "            \n",
    "            # Build a new elastic net model for validation on this subset of wavebands\n",
    "            wv_set_idx = wv_set-350\n",
    "            validator = GridSearchCV(estimator=pipe_elastic_net, param_grid=PARAM_GRID, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=cv_5_0, error_score='raise')\n",
    "            # Like above, special case for phoa\n",
    "            if(gene == \"phoa\"):\n",
    "                validator.fit(X_phoa_train[:,wv_set_idx], y_train)\n",
    "                rmse = validator.score(X_phoa_test[:,wv_set_idx], y_test)\n",
    "            else:\n",
    "                validator.fit(X_train[:,wv_set_idx], y_train)\n",
    "                rmse = validator.score(X_test[:,wv_set_idx], y_test)\n",
    "\n",
    "            # Record each waveband separately. This is difficult to analyze visually, but makes for MUCH easier analysis in R later.\n",
    "            for wv in wv_set:\n",
    "                gene_list.append(gene)\n",
    "                method_list.append(method)\n",
    "                wv_list.append(wv)\n",
    "                rmse_list.append(rmse)\n",
    "                \n",
    "        print(\"Finished \", gene, \".\", sep = \"\")\n",
    "\n",
    "    # Compile the results into a single DataFrame and write it to a CSV\n",
    "    # The format will make for easier analysis later.\n",
    "    print(\"Compiling and writing results to CSV...\", end = \" \")\n",
    "    col_names = ['gene', 'method', 'wv', 'rmse']\n",
    "    results = pd.DataFrame(columns = col_names)\n",
    "    results['gene'] = gene_list\n",
    "    results['method'] = method_list\n",
    "    results['wv'] = wv_list\n",
    "    results['rmse'] = rmse_list\n",
    "    results.to_csv(root + '//results/results.csv', index=False)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d70ab9f9-5fe6-4e67-a177-e48025b4106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting phoa...\n",
      "\tFEATURE SELECTION:\n",
      "\tStarting mutual importance... "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[4.4848554  3.95844697 4.55512055 4.0104626  4.23357341 4.5875232\n 4.45079704 4.50661829 4.50552895 3.1060567  4.1699643  4.43855534\n 3.715521   3.68493464 4.18797634 4.1699643  4.19004384 4.13435481\n 3.16155114 3.85199126 4.46720473 4.25363116 4.36530067 4.77853789\n 4.41326653 4.3247445  2.98492692 4.0104626  3.715521   4.4099934\n 4.14674019 4.4848554  3.85199126 4.63378023 4.14139772 4.46720473\n 3.39120012 3.39120012 4.07618481 4.28022903 4.41326653 3.45764357\n 3.46845245 3.94742937 4.46720473 4.76642846 4.15599308 4.1004451\n 3.0826712  4.36530067 3.45764357 3.77710638 4.35445917 4.14139772\n 4.39135787 3.94742937 4.34494005 4.33334178 4.34494005 4.50207228\n 4.10509871 3.34766036 4.34494005 4.20979039 4.76642846 4.66144624\n 4.48743401 3.63618115 4.50661829 4.44733537 4.48743401 4.23357341\n 4.35445917 4.18797634 4.35445917 4.1699643  4.08286754 4.13435481\n 4.10260098 4.35405635 4.33334178 4.19004384 4.19004384 4.31755535\n 4.59054534 4.77853789 4.0104626  4.07618481 4.63378023 4.26576273\n 4.66144624 4.5875232  4.31755535 3.77710638 3.76911805 4.50661829\n 3.80068635 4.15599308 4.49262718 3.76911805 3.02371446 4.1004451\n 3.39120012 4.32373344 4.18797634 4.49262718 4.66144624 4.41326653\n 3.77710638 4.55790908 4.48743401 4.41326653 3.21246308 4.36415532\n 4.43855534 3.85199126 4.36415532 3.56743144 4.33334178 3.63618115\n 2.98492692 4.14139772 3.16155114 4.36814141 4.36814141 4.19004384\n 3.0826712  3.715521   4.89232736 4.50552895 4.63378023 4.26576273\n 4.20979039 4.36415532 4.55891337 4.33334178 4.47227503 3.94742937\n 4.47227503 3.68493464 4.22386483 3.77710638 4.50207228 4.63378023\n 4.22386483 4.55443239 4.18797634 4.14139772 4.14674019 3.39120012\n 3.45764357 3.0826712  4.49431965 4.89232736 4.59054534 4.15599308\n 4.55443239 3.715521   4.66144624 4.19004384 3.02371446 4.08286754\n 3.46845245 3.1060567  4.1699643  4.28022903 4.0104626  4.31755535\n 3.45764357 4.20979039 4.46720473 3.0826712  3.91097846 3.56743144\n 4.14139772 3.46845245 4.59054534 4.50552895 4.76642846 3.02371446\n 3.63618115 4.89232736 4.25363116 4.76642846 4.18797634 4.44733537\n 4.25363116 4.55790908 3.68493464 4.82904911 3.46845245 4.69298074\n 4.13435481 4.36814141 3.21246308 4.5875232  3.95844697 3.56743144\n 4.48743401 3.80068635 4.55443239 4.50661829 4.50661829 4.10509871\n 3.34766036 4.33334178 3.1060567  4.69298074 4.23357341 4.22386483\n 3.85199126 3.56743144 3.02371446 4.36530067 4.36415532 4.08286754\n 4.55891337 4.07618481 4.82904911 2.98492692 4.35405635 4.08286754\n 4.49262718 3.16155114 4.28022903 4.77853789 4.55443239 4.3247445\n 4.50552895 4.14674019 4.39135787 4.25363116 4.23357341 4.55790908\n 3.77710638 4.49431965 4.36530067 3.68493464 3.34766036 3.91097846\n 4.35405635 2.98492692 3.68493464 4.36814141 4.50207228 4.69298074\n 3.95844697 4.10509871 4.82904911 4.55790908 3.56743144 4.59054534\n 4.48743401 4.49262718 3.21246308 3.80068635 4.35405635 3.63618115\n 4.69298074 3.76911805 4.25363116 4.47227503 3.45764357 4.10260098\n 4.36530067 4.35445917 4.35445917 3.63618115 4.22386483 3.91097846\n 4.4848554  4.43855534 4.14674019 4.4848554  3.91097846 4.07618481\n 4.08286754 4.44733537 4.44733537 4.1004451  4.10260098 4.50207228\n 4.36814141 4.26576273 4.45079704 3.76911805 3.16155114 4.44733537\n 4.5875232  4.34494005 4.55891337 3.21246308 4.31755535 4.15599308\n 4.13435481 4.26576273 4.13435481 4.69298074 4.10260098 3.715521\n 4.4099934  4.55512055 3.91097846 4.1004451  4.20979039 4.10509871\n 4.31755535 4.50207228 4.77853789 4.34494005].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run()\n",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m, in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Where the main calculations happen. Runs each method separately, and then finds the consensus of all of them.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# The phoa special case is due to a different train/test split than the rest because of some NANs.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(gene \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphoa\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     wv_mi, wv_coeffs, wv_ga, wv_cluster, wv_perm_imp, wv_consensus \u001b[38;5;241m=\u001b[39m consensus(X_phoa_train, y_train)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     wv_mi, wv_coeffs, wv_ga, wv_cluster, wv_perm_imp, wv_consensus \u001b[38;5;241m=\u001b[39m consensus(X_train, y_train)\n",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m, in \u001b[0;36mconsensus\u001b[1;34m(X_train, y_train, n_features_intermed, max_features_output)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mFEATURE SELECTION:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mStarting mutual importance...\u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m wv_mi \u001b[38;5;241m=\u001b[39m mi(X_train, y_train, n_features\u001b[38;5;241m=\u001b[39mn_features_intermed)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTraining the elastic net model...\u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mmi\u001b[1;34m(X_train, y_train, n_features)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Uses mutual information to calculate the n_features most related features in X_train to y_train. (Filter method) \"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m----> 4\u001b[0m mi \u001b[38;5;241m=\u001b[39m mutual_info_regression(X_train, y_train)\n\u001b[0;32m      5\u001b[0m top_n_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margpartition(mi, \u001b[38;5;241m-\u001b[39mn_features)[\u001b[38;5;241m-\u001b[39mn_features:]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wvs[top_n_idx]\n",
      "File \u001b[1;32m~\\.conda\\envs\\rkngh_stress\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\rkngh_stress\\Lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:441\u001b[0m, in \u001b[0;36mmutual_info_regression\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state, n_jobs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    326\u001b[0m     {\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    346\u001b[0m ):\n\u001b[0;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate mutual information for a continuous target variable.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m    Mutual information (MI) [1]_ between two random variables is a non-negative\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    array([0.1..., 2.6...  , 0.0...])\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _estimate_mi(\n\u001b[0;32m    442\u001b[0m         X,\n\u001b[0;32m    443\u001b[0m         y,\n\u001b[0;32m    444\u001b[0m         discrete_features\u001b[38;5;241m=\u001b[39mdiscrete_features,\n\u001b[0;32m    445\u001b[0m         discrete_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    446\u001b[0m         n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors,\n\u001b[0;32m    447\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    448\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[0;32m    449\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    450\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\rkngh_stress\\Lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:271\u001b[0m, in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state, n_jobs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimate_mi\u001b[39m(\n\u001b[0;32m    203\u001b[0m     X,\n\u001b[0;32m    204\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    212\u001b[0m ):\n\u001b[0;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate mutual information between the features and the target.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m           Data Sets\". PLoS ONE 9(2), 2014.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m discrete_target)\n\u001b[0;32m    272\u001b[0m     n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(discrete_features, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m)):\n",
      "File \u001b[1;32m~\\.conda\\envs\\rkngh_stress\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[0;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\.conda\\envs\\rkngh_stress\\Lib\\site-packages\\sklearn\\utils\\validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m             )\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[4.4848554  3.95844697 4.55512055 4.0104626  4.23357341 4.5875232\n 4.45079704 4.50661829 4.50552895 3.1060567  4.1699643  4.43855534\n 3.715521   3.68493464 4.18797634 4.1699643  4.19004384 4.13435481\n 3.16155114 3.85199126 4.46720473 4.25363116 4.36530067 4.77853789\n 4.41326653 4.3247445  2.98492692 4.0104626  3.715521   4.4099934\n 4.14674019 4.4848554  3.85199126 4.63378023 4.14139772 4.46720473\n 3.39120012 3.39120012 4.07618481 4.28022903 4.41326653 3.45764357\n 3.46845245 3.94742937 4.46720473 4.76642846 4.15599308 4.1004451\n 3.0826712  4.36530067 3.45764357 3.77710638 4.35445917 4.14139772\n 4.39135787 3.94742937 4.34494005 4.33334178 4.34494005 4.50207228\n 4.10509871 3.34766036 4.34494005 4.20979039 4.76642846 4.66144624\n 4.48743401 3.63618115 4.50661829 4.44733537 4.48743401 4.23357341\n 4.35445917 4.18797634 4.35445917 4.1699643  4.08286754 4.13435481\n 4.10260098 4.35405635 4.33334178 4.19004384 4.19004384 4.31755535\n 4.59054534 4.77853789 4.0104626  4.07618481 4.63378023 4.26576273\n 4.66144624 4.5875232  4.31755535 3.77710638 3.76911805 4.50661829\n 3.80068635 4.15599308 4.49262718 3.76911805 3.02371446 4.1004451\n 3.39120012 4.32373344 4.18797634 4.49262718 4.66144624 4.41326653\n 3.77710638 4.55790908 4.48743401 4.41326653 3.21246308 4.36415532\n 4.43855534 3.85199126 4.36415532 3.56743144 4.33334178 3.63618115\n 2.98492692 4.14139772 3.16155114 4.36814141 4.36814141 4.19004384\n 3.0826712  3.715521   4.89232736 4.50552895 4.63378023 4.26576273\n 4.20979039 4.36415532 4.55891337 4.33334178 4.47227503 3.94742937\n 4.47227503 3.68493464 4.22386483 3.77710638 4.50207228 4.63378023\n 4.22386483 4.55443239 4.18797634 4.14139772 4.14674019 3.39120012\n 3.45764357 3.0826712  4.49431965 4.89232736 4.59054534 4.15599308\n 4.55443239 3.715521   4.66144624 4.19004384 3.02371446 4.08286754\n 3.46845245 3.1060567  4.1699643  4.28022903 4.0104626  4.31755535\n 3.45764357 4.20979039 4.46720473 3.0826712  3.91097846 3.56743144\n 4.14139772 3.46845245 4.59054534 4.50552895 4.76642846 3.02371446\n 3.63618115 4.89232736 4.25363116 4.76642846 4.18797634 4.44733537\n 4.25363116 4.55790908 3.68493464 4.82904911 3.46845245 4.69298074\n 4.13435481 4.36814141 3.21246308 4.5875232  3.95844697 3.56743144\n 4.48743401 3.80068635 4.55443239 4.50661829 4.50661829 4.10509871\n 3.34766036 4.33334178 3.1060567  4.69298074 4.23357341 4.22386483\n 3.85199126 3.56743144 3.02371446 4.36530067 4.36415532 4.08286754\n 4.55891337 4.07618481 4.82904911 2.98492692 4.35405635 4.08286754\n 4.49262718 3.16155114 4.28022903 4.77853789 4.55443239 4.3247445\n 4.50552895 4.14674019 4.39135787 4.25363116 4.23357341 4.55790908\n 3.77710638 4.49431965 4.36530067 3.68493464 3.34766036 3.91097846\n 4.35405635 2.98492692 3.68493464 4.36814141 4.50207228 4.69298074\n 3.95844697 4.10509871 4.82904911 4.55790908 3.56743144 4.59054534\n 4.48743401 4.49262718 3.21246308 3.80068635 4.35405635 3.63618115\n 4.69298074 3.76911805 4.25363116 4.47227503 3.45764357 4.10260098\n 4.36530067 4.35445917 4.35445917 3.63618115 4.22386483 3.91097846\n 4.4848554  4.43855534 4.14674019 4.4848554  3.91097846 4.07618481\n 4.08286754 4.44733537 4.44733537 4.1004451  4.10260098 4.50207228\n 4.36814141 4.26576273 4.45079704 3.76911805 3.16155114 4.44733537\n 4.5875232  4.34494005 4.55891337 3.21246308 4.31755535 4.15599308\n 4.13435481 4.26576273 4.13435481 4.69298074 4.10260098 3.715521\n 4.4099934  4.55512055 3.91097846 4.1004451  4.20979039 4.10509871\n 4.31755535 4.50207228 4.77853789 4.34494005].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50e74600-5db5-4bcf-ae7d-6e45aaa1ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78,)\n"
     ]
    }
   ],
   "source": [
    "print(X_phoa_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
