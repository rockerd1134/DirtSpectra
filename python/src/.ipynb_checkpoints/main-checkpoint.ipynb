{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1c8e74-659c-4624-926c-12fcc27895b2",
   "metadata": {},
   "source": [
    "Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd91d8c-be40-4c4f-b55a-2aa13f2708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.experimental import enable_halving_search_cv # Needed for HalvingGridSearchCV, which is experimental\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "# Add more imports in this block later. There will need to be several \"from sklearn.whatever import something\" lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4168c99b-3a35-4dd1-a31c-f4daaae1880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo('.', search_parent_directories = True)\n",
    "root = repo.working_tree_dir\n",
    "\n",
    "# The sample id and the log-transformed gene expression values.\n",
    "half_data_1 = pd.read_csv(root + '\\\\data\\\\RKNGHStress.csv')\n",
    "half_data_1 = half_data_1.loc[:, half_data_1.columns.str.startswith(('Sample', 'Log'))]\n",
    "half_data_1 = half_data_1.rename(columns = {'Sample' : 'sample', 'Log16S' : 'bact', 'Logcbblr' : 'cbblr', 'Log18S' : 'fungi', 'Logphoa' : 'phoa', 'Logurec' : 'urec'})\n",
    "\n",
    "# The hyperspectral measurements for each sample\n",
    "half_data_2 = pd.read_csv(root + '\\\\data\\\\RKNGHStressPCAPSR.csv')\n",
    "half_data_2 = half_data_2.rename(columns = {'Unnamed: 0' : 'sample'})\n",
    "\n",
    "data = half_data_1.join(half_data_2.set_index('sample'), on = 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d2cc1-a33c-43bc-b1dd-72b2ed921d26",
   "metadata": {},
   "source": [
    "TEMP: testing manual construction of models with specific hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590160bb-bbbd-4c7a-bbba-4b892c5ac65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['sample', 'bact', 'cbblr', 'fungi', 'phoa', 'urec'], axis = 1)\n",
    "# NOTE: when doing phoa, there are a couple of samples (3 and 30) that have no data recorded, so we'll need to remove NAs there. But those observations still have data for the other genes.\n",
    "bact = data[['bact']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "389c2476-08f3-419f-8f01-9be461b04156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: do NOT scale X and y before splitting, since that is a data leak. Instead, use the pipeline to scale both Xs and the y training, and manually scale the y testing for custom scoring like RMSE.\n",
    "X_train, X_test, bact_train, bact_test = train_test_split(X.to_numpy(), bact.to_numpy(), train_size=0.8, random_state=0)\n",
    "#bact_train = scale(bact_train.ravel())\n",
    "#bact_test = scale(bact_test.ravel())\n",
    "\n",
    "# For the sake of robustness, maybe should repeat this a few times, with different random states (still manually set for sake of reproducibility) e.g., 0, 1, ... , 4\n",
    "cv_0 = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "\n",
    "# n_jobs will need to be adjusted later when running on SCINet (high performance computing clusters). -1 uses all available cores, which might cause a bit of thrashing, but good enough for now.\n",
    "# pipeline = make_pipeline(StandardScaler(), ElasticNetCV(alphas = [0.001389495], l1_ratio = 0.4285714, cv = cv_0, selection = 'random', max_iter = 10000, n_jobs = -1))\n",
    "# pipeline.fit(X_train, bact_train)\n",
    "# pipeline.score(X_test, bact_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f46efa-9605-446e-bc1d-91afb144bbe6",
   "metadata": {},
   "source": [
    "This looks weird. None of the folds are converging (true for 10 folds, 5 folds, or even just 1 fold with basic ElasticNet) but changing selection to 'random' and max_iter to 10k allowed convergence. \n",
    "\n",
    "The score is pretty low. But what metric is the score? If it's not RMSE it's not in the ballpark of the R version. (UPDATE: It's R^2, so it's a bunch of pretty bad scores, actually.)\n",
    "\n",
    "It looks like ElasticNetCV, and ElasticNet for that matter, don't allow changing the scoring or tuning metric, or at least it's not obvious how. Can the models be evaluated on RMSE just by calling the RMSE function on the preds and targets? Also, does it even make sense to change the tuning metric for this algorithm? (Idk, you probably COULD, but minimizing the sum of squared residuals is good enough.) And what tuning metric does the tidymodels implementation use?\n",
    "\n",
    "This all might be caused by using the hyperparameter optima found in the R code, but that had a differet train/test split. So it's not optimal here, but it's still probably pretty good, especially since in the analysis of part 1's hyperparameters, there wasn't much variation among the elastic net models' penalties (all tending to be very close to 0) or mixtures (a bit more spread but similar).\n",
    "\n",
    "What happens if some of its own tuning were allowed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c828750-f67b-460c-b8d8-94fd1b31a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Preds on X_test')\n",
    "# print(pipeline.predict(X_test))\n",
    "# print()\n",
    "# print('Scaled bact_test')\n",
    "# print(scale(bact_test))\n",
    "# print()\n",
    "\n",
    "# print('MSE')\n",
    "# mse = mean_squared_error(scale(bact_test), pipeline.predict(X_test))\n",
    "# print(mse)\n",
    "\n",
    "# print('RMSE')\n",
    "# rmse = root_mean_squared_error(scale(bact_test), pipeline.predict(X_test))\n",
    "# print(rmse)\n",
    "# print()\n",
    "\n",
    "# print('MSE, no scaling bact_test')\n",
    "# mse1 = mean_squared_error(bact_test, pipeline.predict(X_test))\n",
    "# print(mse1)\n",
    "# print()\n",
    "\n",
    "# print('RMSE, no scaling bact_test')\n",
    "# rmse1 = root_mean_squared_error(bact_test, pipeline.predict(X_test))\n",
    "# print(rmse1)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23386e86-b543-4d9a-943f-dd7f622db698",
   "metadata": {},
   "source": [
    "Uh oh, RMSE of 0.83 is really bad. It doesn't even come close to the R models. What happened?\n",
    "\n",
    "Looking at the results, it looks like the scaling isn't happening for some reason, or at least not for the predictions. They're all in the 9 range instead of 0 range. Recalculating RMSE after removing scaling on bact_test gave more reasonable results.\n",
    "\n",
    "But the problem is, we want to be able to compare models among different targets using a common scale, so normalization has to be done with respect to other targets (but NOT the entire dataset for each column since that's data leakage). This should be done before training. But how can this be implemented? (UPDATE: Fixed by manually scaling bact_train and bact_test, separately. But still doesn't solve the issue of getting much higher RMSE than expected.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983cfd9-22e6-48d4-930d-34a52c60f7a4",
   "metadata": {},
   "source": [
    "Decided to go back and change the cross validation size to 5 instead of 10 in light of the relatively small dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9ad6d-89e8-4a40-ba49-c661efb9a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing how RMSE changes (hopefully improves!) with hyperparameter tuning\n",
    "\n",
    "# mix_space = np.linspace(0, 1, 8)\n",
    "# reg_space = np.logspace(-5, 5, 8)\n",
    "\n",
    "# elastcv = ElasticNetCV(alphas = reg_space, l1_ratio = mix_space, cv = cv_0, selection = 'random', max_iter = 10000, n_jobs = -1, random_state = 0, positive = True)\n",
    "# estimators_cv = [('scaler', StandardScaler()), ('elastic_net', elastcv)]\n",
    "# pipeline_hp = Pipeline(estimators_cv, memory = root + '\\\\cache')\n",
    "# pipeline_hp.fit(X_train, bact_train)\n",
    "# pipeline_hp.score(X_test, bact_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd1deb-7db8-4dbc-b03e-742ff24d7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('RMSE')\n",
    "# # bact_test has already been scaled above\n",
    "# rmse_hp = root_mean_squared_error(bact_test, pipeline_hp.predict(X_test))\n",
    "# print(rmse_hp)\n",
    "# print()\n",
    "\n",
    "# print(pipeline_hp['elastic_net'].get_params())\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af218112-f933-4e6a-aca4-cf1ef8d73906",
   "metadata": {},
   "source": [
    "This sucks. The results are even worse than before. I must have done something wrong here, but I haven't figured out what yet. Also I'm trying to figure out what the hyperparameters were that it ended up on. Maybe it's better to just do ElasticNet and the parameter search separately in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0646a-ef83-4588-bc88-0b4297ed3563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pipe = Pipeline(\n",
    "#     [\n",
    "#         (\"scaler\", StandardScaler()),\n",
    "#         (\"elastic_net\", ElasticNet(warm_start=True, positive=True, random_state=0, selection=\"random\"))\n",
    "#     ],\n",
    "#     memory = root+'\\\\cache'\n",
    "# )\n",
    "\n",
    "# REGULARIZATION = np.logspace(-5, 5, 8) # If this doesn't work, may have to enclose the RHS in list()\n",
    "# MIXTURE = np.linspace(0, 1, 8)\n",
    "# PARAM_GRID = [\n",
    "#     {\n",
    "#         \"elastic_net__alpha\": REGULARIZATION,\n",
    "#         \"elastic_net__l1_ratio\": MIXTURE\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# hgrid = HalvingGridSearchCV(estimator=pipe, param_grid=PARAM_GRID, factor=2, n_jobs=-1, cv=5, verbose=2, error_score='raise')\n",
    "# hgrid.fit(X_train, bact_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50da35c-10e5-48bf-9c3f-7fc880faf3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hgrid.score(X_test, bact_test))\n",
    "# print('RMSE:', root_mean_squared_error(bact_test, hgrid.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451a8d1-786a-4839-a932-7edade4490e0",
   "metadata": {},
   "source": [
    "Still need to do a postmortem here, but at least the halving search converged quickly...?\n",
    "\n",
    "I think the issue might be up top when reading in the data. Maybe I made a mistake reading it in, or scaling it, or something I haven't thought of yet. If the issue is with scaling it and the pipeline, maybe try manually scaling and manually using an estimator to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a212ed-f7ba-46ca-9b7d-07b12071f58c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Checklist:\n",
    "# # data doesn't have any obvious problems that I can see, except for the missing phoa data for two samples\n",
    "# # bact looks okay\n",
    "# # X looks okay\n",
    "# # X_train and bact_train have corresponding shapes\n",
    "# # Same for _test\n",
    "# # No obvious problems with X_train, bact_train, X_test, or bact_test\n",
    "\n",
    "# hgrid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f268e-47ef-4765-81b7-39e1621008c5",
   "metadata": {},
   "source": [
    "Now the halving grid search is giving a bunch of nan values during training, and clean R2=0.0 and RMSE=1.0 vals. How did this get even worse??? I only manually deleted the two outlier lines from the csv. Next step: try switching to Grid search. If that doesn't work, try manually scaling and then manually fitting elastic net. Also check if I gave it bad hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca6561-12fa-4cf9-a952-a196e74c128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(estimator=pipe, param_grid=PARAM_GRID, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=5, verbose=2, error_score='raise')\n",
    "# grid.fit(X_train, bact_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed78d1-a806-4a7c-95ec-c63310f03b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('best estimator:', grid.best_estimator_)\n",
    "# print()\n",
    "# print('best RMSE:', grid.best_score_*-1)\n",
    "# print()\n",
    "# print('best params:', grid.best_params_)\n",
    "# print()\n",
    "# print('preds on train:', grid.predict(X_train))\n",
    "# print()\n",
    "# print('preds on test:', grid.predict(X_test))\n",
    "# print()\n",
    "# best_estimator = grid.best_estimator_\n",
    "# print('model coeffs:', best_estimator['elastic_net'].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60de53-7d0c-4a55-8704-1620a7431c38",
   "metadata": {},
   "source": [
    "I think I found the reason all of this is so screwed up. It's predicting (basically) 0 for all input features, which IS the mean of the input data for each column, but it's still a blind guess. All the model coefficients are zero, which is why it's predicting zero every time. Maybe something went wrong with the scaling, then.\n",
    "\n",
    "UPDATE: I just double checked with the previous R code, and I didn't normalize the target variables there. (But should I have? It would make cross-target RMSE directly comparable...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862f7eb-994c-44aa-9831-9d6ecb33410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing to see if scaling is doing what I think it's doing\n",
    "# toy = np.arange(12).reshape((4,3))\n",
    "# print(toy)\n",
    "# print()\n",
    "# print(scale(toy))\n",
    "# print()\n",
    "# print(np.mean(scale(toy), axis=0))\n",
    "# print()\n",
    "# print(np.std(scale(toy), axis=0))\n",
    "\n",
    "# Yup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c7646d-a9d6-4d22-aa16-24ee8bb2496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing if maybe there's something going on within the hyperparameter tuning, and that was overfit\n",
    "# test_pipe = Pipeline(\n",
    "#     [\n",
    "#         (\"scaler\", StandardScaler()),\n",
    "#         (\"elastic_net\", ElasticNet(warm_start=True, positive=True, random_state=0, selection=\"random\"))\n",
    "#     ],\n",
    "#     memory = root+'\\\\cache'\n",
    "# )\n",
    "\n",
    "# test_pipe.fit(X_train, bact_train)\n",
    "# test_pipe['elastic_net'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd4030-d7c0-438d-b641-ae4e93b29a29",
   "metadata": {},
   "source": [
    "Yeah, this has the same issue. So the problem probably isn't in the cross validation, but in the preprocessing (scaling or train/test splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4c32e-cbc8-4fba-8cfa-7536c56095ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing if the issue is with scaling bact_train and bact_test\n",
    "# en = ElasticNet(warm_start=True, positive=True, random_state=0, selection='random')\n",
    "# en.fit(X_train, bact_train_noscale)\n",
    "# print(en.score(X_train, bact_train_noscale))\n",
    "# print(en.score(X_test, bact_test_noscale))\n",
    "# print(en.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cdbd80-79bc-4802-a7ef-b3d188216934",
   "metadata": {},
   "source": [
    "Doesn't appear that the issue is with scaling y, although I didn't really expect it to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2da81-8255-43a4-ba88-6bf8311f0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled = scale(X_train)\n",
    "# X_test_scaled = scale(X_test)\n",
    "# en1 = ElasticNet(warm_start=True, positive=True, random_state=0, selection='random')\n",
    "# en1.fit(X_train_scaled, bact_train)\n",
    "# print(en1.score(X_train_scaled, bact_train))\n",
    "# print(en1.score(X_test_scaled, bact_test))\n",
    "# print(en1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8490b05-0b99-401d-9cee-4e73e8a73fee",
   "metadata": {},
   "source": [
    "Similarly, manually scaling X doesn't fix the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cfacae-2e6b-478e-a3e4-bfabbd36dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en2 = ElasticNet(warm_start=True, positive=True, random_state=0, selection='random')\n",
    "# en2.fit(X_train, bact_train)\n",
    "# print(en2.score(X_train, bact_train))\n",
    "# print(en2.score(X_test, bact_test))\n",
    "# print(en2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31062509-f8db-42e2-8193-ef6cd06f5571",
   "metadata": {},
   "source": [
    "And not scaling X doesn't either. Now test train_test_split to see if something's going on there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1bc69d-9b03-41b5-8ac1-3ec967cbe717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(data.head(n=15))\n",
    "# print('-----------------------------------------')\n",
    "# print(X.head())\n",
    "# print('-----------------------------------------')\n",
    "# print(bact.head(n=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303bdfa-8b6e-4843-955c-3a217bccf852",
   "metadata": {},
   "source": [
    "Nothing surprising here, it all looks like it should, from what I can tell..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618893b-ee25-42b2-9a60-a34b48846bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, bact_train, bact_test = train_test_split(X.to_numpy(), bact.to_numpy(), train_size = 0.8, random_state = 0)\n",
    "# # Testing if maybe there's something going on within the hyperparameter tuning, and that was overfit\n",
    "# test_pipe = Pipeline(\n",
    "#     [\n",
    "#         (\"scaler\", StandardScaler()),\n",
    "#         (\"lin_reg\", LinearRegression(positive=True))\n",
    "#     ],\n",
    "#     memory = root+'\\\\cache'\n",
    "# )\n",
    "\n",
    "# test_pipe = test_pipe.fit(X_train, bact_train)\n",
    "# print(test_pipe['lin_reg'].coef_)\n",
    "# print(test_pipe.score(X_test, bact_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991429d-f018-4117-ac6d-51670a8d18fc",
   "metadata": {},
   "source": [
    "Just played around with different random_state vals for the split, and coeffs are still 0. Also tried doing just a basic linear regression, and same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66987d-12e8-4ceb-a87b-e904714e38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, bact_train, bact_test = train_test_split(X, bact, train_size = 0.8, random_state = 0)\n",
    "# test_pipe = Pipeline(\n",
    "#     [\n",
    "#         (\"scaler\", StandardScaler()),\n",
    "#         (\"elastic_net\", ElasticNet(warm_start=True, positive=True, random_state=0, selection='random'))\n",
    "#     ],\n",
    "#     memory = root+'\\\\cache',\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# REGULARIZATION = np.logspace(-5, 5, 8) # If this doesn't work, may have to enclose the RHS in list()\n",
    "# MIXTURE = np.linspace(0, 1, 8)\n",
    "# PARAM_GRID = [\n",
    "#     {\n",
    "#         \"elastic_net__alpha\": REGULARIZATION,\n",
    "#         \"elastic_net__l1_ratio\": MIXTURE\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# grid = GridSearchCV(estimator=test_pipe, param_grid=PARAM_GRID, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=cv_0, verbose=2, error_score='raise')\n",
    "# grid.fit(X_train, bact_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f6aa00-3a40-4f39-b2ad-9c55aa94230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid.score(X_train, bact_train))\n",
    "# print(grid.score(X_test, bact_test))\n",
    "# print(grid)\n",
    "# print(grid.best_estimator_.named_steps['elastic_net'].coef_)\n",
    "# print()\n",
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422ac8d-aaf2-47d6-83e8-cfcdad72d521",
   "metadata": {},
   "source": [
    "No idea why it's all zeros. Does it work for random forests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08a593-01e8-4590-8c0e-c2b419a6f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor()\n",
    "# rf.fit(X_train, bact_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e340919-643b-44d1-9714-8a8d44028d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rf.score(X_train, bact_train))\n",
    "# print(rf.score(X_test, bact_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f23b3-d116-4819-8bc9-56ea587a1a4d",
   "metadata": {},
   "source": [
    "Well it overfit pretty badly on this, but I didn't put any effort into tuning hyperparameters so that's reasonable enough. At least it didn't give an abysmal score on the test set too... what's going on???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfb2a6b7-a0e8-40aa-b180-fb96adca0eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 2 of 2) Processing elastic_net, total=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(memory=&#x27;C:\\\\Users\\\\joshua.waldbieser\\\\OneDrive &#x27;\n",
       "                                       &#x27;- &#x27;\n",
       "                                       &#x27;USDA\\\\root_knot_nematode_greenhouse\\\\paper_2\\\\DirtSpectra\\\\cache&#x27;,\n",
       "                                steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;elastic_net&#x27;,\n",
       "                                        ElasticNet(fit_intercept=False,\n",
       "                                                   max_iter=4000,\n",
       "                                                   random_state=0,\n",
       "                                                   selection=&#x27;random&#x27;,\n",
       "                                                   war...ue))],\n",
       "                                verbose=True),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;elastic_net__alpha&#x27;: array([1.00000000e-05, 2.68269580e-04, 7.19685673e-03, 1.93069773e-01,\n",
       "       5.17947468e+00, 1.38949549e+02, 3.72759372e+03, 1.00000000e+05]),\n",
       "                          &#x27;elastic_net__l1_ratio&#x27;: array([0.01      , 0.15142857, 0.29285714, 0.43428571, 0.57571429,\n",
       "       0.71714286, 0.85857143, 1.        ])}],\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(memory=&#x27;C:\\\\Users\\\\joshua.waldbieser\\\\OneDrive &#x27;\n",
       "                                       &#x27;- &#x27;\n",
       "                                       &#x27;USDA\\\\root_knot_nematode_greenhouse\\\\paper_2\\\\DirtSpectra\\\\cache&#x27;,\n",
       "                                steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;elastic_net&#x27;,\n",
       "                                        ElasticNet(fit_intercept=False,\n",
       "                                                   max_iter=4000,\n",
       "                                                   random_state=0,\n",
       "                                                   selection=&#x27;random&#x27;,\n",
       "                                                   war...ue))],\n",
       "                                verbose=True),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;elastic_net__alpha&#x27;: array([1.00000000e-05, 2.68269580e-04, 7.19685673e-03, 1.93069773e-01,\n",
       "       5.17947468e+00, 1.38949549e+02, 3.72759372e+03, 1.00000000e+05]),\n",
       "                          &#x27;elastic_net__l1_ratio&#x27;: array([0.01      , 0.15142857, 0.29285714, 0.43428571, 0.57571429,\n",
       "       0.71714286, 0.85857143, 1.        ])}],\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=5)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(memory=&#x27;C:\\\\Users\\\\joshua.waldbieser\\\\OneDrive - &#x27;\n",
       "                &#x27;USDA\\\\root_knot_nematode_greenhouse\\\\paper_2\\\\DirtSpectra\\\\cache&#x27;,\n",
       "         steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;elastic_net&#x27;,\n",
       "                 ElasticNet(alpha=np.float64(0.0071968567300115215),\n",
       "                            fit_intercept=False,\n",
       "                            l1_ratio=np.float64(0.7171428571428572),\n",
       "                            max_iter=4000, random_state=0, selection=&#x27;random&#x27;,\n",
       "                            warm_start=True))],\n",
       "         verbose=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=np.float64(0.0071968567300115215), fit_intercept=False,\n",
       "           l1_ratio=np.float64(0.7171428571428572), max_iter=4000,\n",
       "           random_state=0, selection=&#x27;random&#x27;, warm_start=True)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             error_score='raise',\n",
       "             estimator=Pipeline(memory='C:\\\\Users\\\\joshua.waldbieser\\\\OneDrive '\n",
       "                                       '- '\n",
       "                                       'USDA\\\\root_knot_nematode_greenhouse\\\\paper_2\\\\DirtSpectra\\\\cache',\n",
       "                                steps=[('scaler', StandardScaler()),\n",
       "                                       ('elastic_net',\n",
       "                                        ElasticNet(fit_intercept=False,\n",
       "                                                   max_iter=4000,\n",
       "                                                   random_state=0,\n",
       "                                                   selection='random',\n",
       "                                                   war...ue))],\n",
       "                                verbose=True),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'elastic_net__alpha': array([1.00000000e-05, 2.68269580e-04, 7.19685673e-03, 1.93069773e-01,\n",
       "       5.17947468e+00, 1.38949549e+02, 3.72759372e+03, 1.00000000e+05]),\n",
       "                          'elastic_net__l1_ratio': array([0.01      , 0.15142857, 0.29285714, 0.43428571, 0.57571429,\n",
       "       0.71714286, 0.85857143, 1.        ])}],\n",
       "             scoring='neg_root_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"elastic_net\", ElasticNet(fit_intercept=False, warm_start=True, random_state=0, selection='random', max_iter=4000))\n",
    "    ],\n",
    "    memory = root+'\\\\cache',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "REGULARIZATION = np.logspace(-5, 5, 8) # If this doesn't work, may have to enclose the RHS in list()\n",
    "MIXTURE = np.linspace(0.01, 1, 8)\n",
    "PARAM_GRID = [\n",
    "    {\n",
    "        \"elastic_net__alpha\": REGULARIZATION,\n",
    "        \"elastic_net__l1_ratio\": MIXTURE\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(estimator=test_pipe, param_grid=PARAM_GRID, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=cv_0, verbose=5, error_score='raise')\n",
    "grid.fit(X_train, bact_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a1d976c-dfa2-4dff-99d6-5c17355f2f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.774161215484327\n",
      "-9.864287106480068\n",
      "9.864287106480068\n",
      "\n",
      "[ 0.05653116  0.         -0.         ...  0.          0.\n",
      "  0.05158106]\n",
      "[ 0.05653116 -0.10201965 -0.00856577 -0.09334213  0.05752763 -0.00344667\n",
      "  0.0101652  -0.35378196 -0.0642535   0.0128382   0.18810579  0.13344227\n",
      "  0.08249823  0.03967344  0.00244845  0.02410556  0.04329378  0.0498761\n",
      "  0.0477586   0.0300533   0.00070817  0.00440714  0.02074096  0.0138361\n",
      " -0.15486479 -0.24240432 -0.11159019  0.1923752   0.17299518 -0.04100288\n",
      " -0.09912229 -0.00473551 -0.04189615 -0.07234951  0.00372444  0.01726481\n",
      "  0.04206772  0.03383381  0.00117051  0.05158106]\n"
     ]
    }
   ],
   "source": [
    "print(grid.score(X_train, bact_train))\n",
    "print(grid.score(X_test, bact_test))\n",
    "print(root_mean_squared_error(bact_test, grid.predict(X_test)))\n",
    "print()\n",
    "\n",
    "coeffs = grid.best_estimator_.named_steps['elastic_net'].coef_\n",
    "print(coeffs)\n",
    "nonzeros = coeffs[coeffs != 0.0]\n",
    "print(nonzeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d3625-829e-4c88-a870-aa9dbe3dcc9e",
   "metadata": {},
   "source": [
    "Changing the elastic net hyperparameter from positive=False to True (default) solved the all-zero coefficient problem. I also tweaked MIXTURE to avoid the endpoint of 0, and max_iter=4000 (default was 1000), since the previous options led to nonconvergence because of numerical/implementation inefficiencies behind the scenes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1cc52-458d-4efa-991e-f29087f509a9",
   "metadata": {},
   "source": [
    "But there's still a problem with unexpectedly poor RMSE results. When normalizing y, gives RMSE about 0.7, and when not normalizing, RMSE about 9.8."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
